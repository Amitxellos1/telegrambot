# ğŸ¤– Telegram RAG Bot

A lightweight GenAI Telegram bot that uses **Retrieval Augmented Generation (RAG)** to answer questions from a knowledge base and can describe images using vision models.

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![Telegram](https://img.shields.io/badge/Telegram-Bot-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

## âœ¨ Features

- ğŸ“š **RAG-based Q&A**: Answers questions using retrieved context from document knowledge base
- ğŸ–¼ï¸ **Image Description**: Describes uploaded images using vision models
- ğŸ’¬ **Conversation History**: Maintains last 3 interactions per user for context-aware responses
- ğŸ” **Source Attribution**: Shows which documents were used to generate answers
- ğŸ“ **Conversation Summary**: Summarize recent chat history
- âš¡ **Query Caching**: Caches embeddings for repeated queries

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Telegram      â”‚â”€â”€â”€â”€â–¶â”‚   Bot Server    â”‚â”€â”€â”€â”€â–¶â”‚   RAG Pipeline  â”‚
â”‚   User          â”‚â—€â”€â”€â”€â”€â”‚   (bot.py)      â”‚â—€â”€â”€â”€â”€â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â”‚                        â–¼
                                â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚               â”‚   Embedder      â”‚
                                â”‚               â”‚ (sentence-      â”‚
                                â”‚               â”‚  transformers)  â”‚
                                â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â”‚                        â–¼
                                â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚               â”‚   ChromaDB      â”‚
                                â”‚               â”‚  Vector Store   â”‚
                                â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   LLM Client    â”‚â—€â”€â”€â”€â”€â”‚   Retrieved     â”‚
                        â”‚ (OpenAI/Ollama) â”‚     â”‚   Context       â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
Avivo_task/
â”œâ”€â”€ bot.py                 # Main Telegram bot application
â”œâ”€â”€ config.py              # Configuration management
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ env.example.txt        # Environment variables template
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ __init__.py        # RAG module exports
â”‚   â”œâ”€â”€ embedder.py        # Text embedding & chunking
â”‚   â”œâ”€â”€ retriever.py       # Vector search with ChromaDB
â”‚   â””â”€â”€ llm.py             # LLM clients (OpenAI/Ollama)
â”œâ”€â”€ data/                  # Knowledge base documents
â”‚   â”œâ”€â”€ company_policies.md
â”‚   â”œâ”€â”€ tech_faq.md
â”‚   â”œâ”€â”€ product_info.md
â”‚   â”œâ”€â”€ onboarding_guide.md
â”‚   â””â”€â”€ security_guidelines.md
â””â”€â”€ db/                    # ChromaDB persistence directory
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- Telegram account
- OpenAI API key (or Ollama installed locally)

### 1. Clone and Setup

```bash
# Navigate to project directory
cd Avivo_task

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Create Telegram Bot

1. Open Telegram and search for **@BotFather**
2. Send `/newbot` and follow the prompts
3. Copy the bot token you receive

### 3. Configure Environment

1. Copy `env.example.txt` to `.env`:
   ```bash
   # Windows
   copy env.example.txt .env
   # Linux/Mac
   cp env.example.txt .env
   ```

2. Edit `.env` with your credentials:
   ```
   TELEGRAM_BOT_TOKEN=your_bot_token_here
   OPENAI_API_KEY=your_openai_key_here
   ```

### 4. Run the Bot

```bash
python bot.py
```

The bot will:
1. Initialize the embedding model
2. Index documents from `data/` directory (first run only)
3. Start listening for Telegram messages

## ğŸ“± Bot Commands

| Command | Description |
|---------|-------------|
| `/start` | Welcome message and introduction |
| `/ask <question>` | Ask a question from the knowledge base |
| `/image` | Describe an uploaded image |
| `/sources` | Show documents used in last answer |
| `/summarize` | Summarize recent conversation |
| `/help` | Show help message |

### Example Usage

```
User: /ask What is the remote work policy?
Bot: ğŸ“ Answer:
     Employees are eligible for remote work after completing their 
     3-month probation period. Remote work requests must be submitted 
     to HR at least one week in advance...
     
     ğŸ“š Sources: company_policies.md
```

## âš™ï¸ Configuration Options

| Variable | Description | Default |
|----------|-------------|---------|
| `TELEGRAM_BOT_TOKEN` | Your Telegram bot token | Required |
| `LLM_PROVIDER` | LLM provider (`openai` or `ollama`) | `openai` |
| `OPENAI_API_KEY` | OpenAI API key | Required for OpenAI |
| `OPENAI_MODEL` | OpenAI model name | `gpt-4o-mini` |
| `OLLAMA_MODEL` | Ollama model for text | `mistral` |
| `OLLAMA_VISION_MODEL` | Ollama model for images | `llava` |
| `EMBEDDING_MODEL` | Sentence transformer model | `all-MiniLM-L6-v2` |
| `TOP_K_RESULTS` | Number of documents to retrieve | `3` |
| `MAX_HISTORY_PER_USER` | Conversation history length | `3` |

## ğŸ”§ Using Ollama (Local LLM)

For fully local operation without API costs:

1. Install Ollama from [ollama.ai](https://ollama.ai)

2. Pull required models:
   ```bash
   ollama pull mistral
   ollama pull llava  # For image description
   ```

3. Update `.env`:
   ```
   LLM_PROVIDER=ollama
   OLLAMA_HOST=http://localhost:11434
   ```

4. Run the bot:
   ```bash
   python bot.py
   ```

## ğŸ³ Docker Deployment (Optional)

Create a `Dockerfile`:

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["python", "bot.py"]
```

Build and run:

```bash
docker build -t telegram-rag-bot .
docker run -d --env-file .env telegram-rag-bot
```

## ğŸ“š Adding Custom Documents

1. Add your `.md` files to the `data/` directory
2. Delete the `db/` folder to force re-indexing
3. Restart the bot

The bot will automatically:
- Load all `.md` files
- Split them into chunks
- Generate embeddings
- Store in ChromaDB

## ğŸ¯ Tech Stack

| Component | Technology |
|-----------|------------|
| **Bot Framework** | python-telegram-bot 21.x |
| **Embeddings** | sentence-transformers (all-MiniLM-L6-v2) |
| **Vector Store** | ChromaDB |
| **LLM** | OpenAI GPT-4o-mini / Ollama |
| **Image Description** | GPT-4o-mini Vision / LLaVA |

## ğŸ“Š Model Selection Rationale

- **all-MiniLM-L6-v2**: Fast, lightweight (80MB), good quality embeddings. Ideal for local deployment.
- **GPT-4o-mini**: Cost-effective, fast responses, supports vision. Best balance of quality and price.
- **Ollama + Mistral**: Free, runs locally, good quality. Best for privacy-focused deployments.

## ğŸ”’ Security Considerations

- Never commit `.env` file to version control
- Use environment variables for all secrets
- Consider rate limiting for production deployments
- Validate and sanitize user inputs

## ğŸ“ License

MIT License - feel free to use and modify.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request


